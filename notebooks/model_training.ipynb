{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Promethium: Model Training Tutorial\n",
                "\n",
                "This notebook demonstrates how to train reconstruction models using the Promethium framework.\n",
                "\n",
                "**Author:** Olaf Yunus Laitinen Imanov  \n",
                "**Date:** December 2025  \n",
                "**Framework:** Promethium v1.0.0"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "\n",
                "from promethium.ml.models import UNet\n",
                "from promethium.ml.training import Trainer\n",
                "from promethium.ml.data import SeismicDataset\n",
                "\n",
                "print(f\"PyTorch version: {torch.__version__}\")\n",
                "print(f\"CUDA available: {torch.cuda.is_available()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Configure Training\n",
                "\n",
                "Set up training parameters and data paths."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "config = {\n",
                "    \"model\": {\n",
                "        \"architecture\": \"unet\",\n",
                "        \"in_channels\": 1,\n",
                "        \"out_channels\": 1,\n",
                "        \"features\": [64, 128, 256, 512]\n",
                "    },\n",
                "    \"training\": {\n",
                "        \"epochs\": 100,\n",
                "        \"batch_size\": 16,\n",
                "        \"learning_rate\": 1e-4,\n",
                "        \"weight_decay\": 1e-5\n",
                "    },\n",
                "    \"data\": {\n",
                "        \"train_path\": \"data/train\",\n",
                "        \"val_path\": \"data/val\",\n",
                "        \"patch_size\": 256\n",
                "    }\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize Model\n",
                "\n",
                "Create the U-Net model for reconstruction."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = UNet(\n",
                "    in_channels=config[\"model\"][\"in_channels\"],\n",
                "    out_channels=config[\"model\"][\"out_channels\"],\n",
                "    features=config[\"model\"][\"features\"]\n",
                ")\n",
                "\n",
                "# Move to GPU if available\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "model = model.to(device)\n",
                "\n",
                "# Print model summary\n",
                "total_params = sum(p.numel() for p in model.parameters())\n",
                "print(f\"Model parameters: {total_params:,}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Prepare Data\n",
                "\n",
                "Create data loaders for training and validation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import DataLoader\n",
                "\n",
                "# Create datasets\n",
                "train_dataset = SeismicDataset(\n",
                "    config[\"data\"][\"train_path\"],\n",
                "    patch_size=config[\"data\"][\"patch_size\"]\n",
                ")\n",
                "\n",
                "val_dataset = SeismicDataset(\n",
                "    config[\"data\"][\"val_path\"],\n",
                "    patch_size=config[\"data\"][\"patch_size\"]\n",
                ")\n",
                "\n",
                "# Create data loaders\n",
                "train_loader = DataLoader(\n",
                "    train_dataset,\n",
                "    batch_size=config[\"training\"][\"batch_size\"],\n",
                "    shuffle=True,\n",
                "    num_workers=4\n",
                ")\n",
                "\n",
                "val_loader = DataLoader(\n",
                "    val_dataset,\n",
                "    batch_size=config[\"training\"][\"batch_size\"],\n",
                "    shuffle=False,\n",
                "    num_workers=4\n",
                ")\n",
                "\n",
                "print(f\"Training samples: {len(train_dataset)}\")\n",
                "print(f\"Validation samples: {len(val_dataset)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train Model\n",
                "\n",
                "Run the training loop with validation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "trainer = Trainer(\n",
                "    model=model,\n",
                "    train_loader=train_loader,\n",
                "    val_loader=val_loader,\n",
                "    learning_rate=config[\"training\"][\"learning_rate\"],\n",
                "    weight_decay=config[\"training\"][\"weight_decay\"],\n",
                "    device=device\n",
                ")\n",
                "\n",
                "# Train for specified epochs\n",
                "history = trainer.fit(epochs=config[\"training\"][\"epochs\"])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Training\n",
                "\n",
                "Plot training and validation losses."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
                "plt.plot(history[\"val_loss\"], label=\"Validation Loss\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Loss\")\n",
                "plt.title(\"Training Progress\")\n",
                "plt.legend()\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Model\n",
                "\n",
                "Save the trained model for inference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model checkpoint\n",
                "torch.save({\n",
                "    \"model_state_dict\": model.state_dict(),\n",
                "    \"config\": config,\n",
                "    \"history\": history\n",
                "}, \"checkpoints/unet_trained.pt\")\n",
                "\n",
                "print(\"Model saved successfully\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "**Promethium** - State-of-the-art seismic data reconstruction"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}